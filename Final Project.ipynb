{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IST - 707 Data Analytics\n",
    "**Saheb Singh** <br>\n",
    "**Laxman Kumar** <br>\n",
    "**Abhiraj Singh**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame, Series\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from scipy.spatial import distance_matrix\n",
    "from sklearn.cluster import KMeans,AgglomerativeClustering\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, precision_score, recall_score, f1_score, roc_curve, roc_auc_score, accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from IPython.display import Image\n",
    "from xgboost import XGBClassifier\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation,Dropout\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "import pydotplus\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "import seaborn as sns\n",
    "import math\n",
    "import os\n",
    "import plotly.graph_objects as go\n",
    "import seaborn as sns; sns.set()\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data.csv')\n",
    "#df = pd.read_csv('CleanedMerged.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the number of rows and columns in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5144, 145)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 5144 numbers of rows. And each row has 145 number of columns. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selecting Relevant Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We looked at our dataset and our data description, and looked at the relevant columns. Therefore we would only select those columns which are relevant. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = ['date', 'B_fighter', 'R_fighter', 'Winner', 'B_current_lose_streak',\n",
    "       'B_current_win_streak', 'B_draw', 'B_longest_win_streak', 'B_losses',\n",
    "       'B_total_rounds_fought', 'B_total_title_bouts',\n",
    "       'B_win_by_Decision_Majority', 'B_win_by_Decision_Split',\n",
    "       'B_win_by_Decision_Unanimous', 'B_win_by_KO/TKO', 'B_win_by_Submission',\n",
    "       'B_win_by_TKO_Doctor_Stoppage', 'B_wins', 'B_Stance', 'B_Height_cms',\n",
    "       'B_Reach_cms', 'B_Weight_lbs', 'R_current_lose_streak',\n",
    "       'R_current_win_streak', 'R_draw', 'R_longest_win_streak', 'R_losses',\n",
    "       'R_total_rounds_fought', 'R_total_title_bouts',\n",
    "       'R_win_by_Decision_Majority', 'R_win_by_Decision_Split',\n",
    "       'R_win_by_Decision_Unanimous', 'R_win_by_KO/TKO', 'R_win_by_Submission',\n",
    "       'R_win_by_TKO_Doctor_Stoppage', 'R_wins', 'R_Stance', 'R_Height_cms',\n",
    "       'R_Reach_cms', 'R_Weight_lbs', 'B_age', 'R_age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[a]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shape of the new Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5144, 42)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fixing the datetime in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date'] = pd.to_datetime(df['date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Replacing empty string with nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.replace(r'^\\s*$', np.nan, regex=True)\n",
    "df = df.fillna(np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Renaming some of our columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={\"B_win_by_KO/TKO\": \"B_win_by_KO_TKO\", \"R_win_by_KO/TKO\": \"R_win_by_KO_TKO\"},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Red', 'Blue', 'Draw'], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting the list of target variables\n",
    "df.Winner.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing Draws \n",
    "As this is a binary classification. We are only taking Winner and Looser, therefore we are removing all the rows where the result is Draw. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.Winner != 'Draw']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Viewing basic statistics about the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>B_current_lose_streak</th>\n",
       "      <th>B_current_win_streak</th>\n",
       "      <th>B_draw</th>\n",
       "      <th>B_longest_win_streak</th>\n",
       "      <th>B_losses</th>\n",
       "      <th>B_total_rounds_fought</th>\n",
       "      <th>B_total_title_bouts</th>\n",
       "      <th>B_win_by_Decision_Majority</th>\n",
       "      <th>B_win_by_Decision_Split</th>\n",
       "      <th>B_win_by_Decision_Unanimous</th>\n",
       "      <th>...</th>\n",
       "      <th>R_win_by_Decision_Unanimous</th>\n",
       "      <th>R_win_by_KO_TKO</th>\n",
       "      <th>R_win_by_Submission</th>\n",
       "      <th>R_win_by_TKO_Doctor_Stoppage</th>\n",
       "      <th>R_wins</th>\n",
       "      <th>R_Height_cms</th>\n",
       "      <th>R_Reach_cms</th>\n",
       "      <th>R_Weight_lbs</th>\n",
       "      <th>B_age</th>\n",
       "      <th>R_age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5061.000000</td>\n",
       "      <td>5061.000000</td>\n",
       "      <td>5061.0</td>\n",
       "      <td>5061.000000</td>\n",
       "      <td>5061.000000</td>\n",
       "      <td>5061.000000</td>\n",
       "      <td>5061.000000</td>\n",
       "      <td>5061.000000</td>\n",
       "      <td>5061.000000</td>\n",
       "      <td>5061.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>5061.000000</td>\n",
       "      <td>5061.000000</td>\n",
       "      <td>5061.000000</td>\n",
       "      <td>5061.000000</td>\n",
       "      <td>5061.000000</td>\n",
       "      <td>5057.000000</td>\n",
       "      <td>4752.000000</td>\n",
       "      <td>5058.000000</td>\n",
       "      <td>4891.000000</td>\n",
       "      <td>4998.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.429955</td>\n",
       "      <td>0.833235</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.585062</td>\n",
       "      <td>1.462754</td>\n",
       "      <td>8.903972</td>\n",
       "      <td>0.277811</td>\n",
       "      <td>0.016993</td>\n",
       "      <td>0.211421</td>\n",
       "      <td>0.778502</td>\n",
       "      <td>...</td>\n",
       "      <td>1.178423</td>\n",
       "      <td>1.254100</td>\n",
       "      <td>0.778502</td>\n",
       "      <td>0.071725</td>\n",
       "      <td>3.600869</td>\n",
       "      <td>179.293763</td>\n",
       "      <td>183.682837</td>\n",
       "      <td>172.075326</td>\n",
       "      <td>29.175833</td>\n",
       "      <td>29.427371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.730263</td>\n",
       "      <td>1.284542</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.771906</td>\n",
       "      <td>1.865975</td>\n",
       "      <td>11.242031</td>\n",
       "      <td>1.107056</td>\n",
       "      <td>0.130777</td>\n",
       "      <td>0.525210</td>\n",
       "      <td>1.294768</td>\n",
       "      <td>...</td>\n",
       "      <td>1.602733</td>\n",
       "      <td>1.792344</td>\n",
       "      <td>1.327774</td>\n",
       "      <td>0.278677</td>\n",
       "      <td>3.708439</td>\n",
       "      <td>8.651769</td>\n",
       "      <td>10.309217</td>\n",
       "      <td>35.168220</td>\n",
       "      <td>4.078995</td>\n",
       "      <td>4.140642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>152.400000</td>\n",
       "      <td>152.400000</td>\n",
       "      <td>115.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>172.720000</td>\n",
       "      <td>177.800000</td>\n",
       "      <td>145.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>26.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>180.340000</td>\n",
       "      <td>185.420000</td>\n",
       "      <td>170.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>29.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>185.420000</td>\n",
       "      <td>190.500000</td>\n",
       "      <td>185.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>32.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>210.820000</td>\n",
       "      <td>213.360000</td>\n",
       "      <td>345.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>47.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       B_current_lose_streak  B_current_win_streak  B_draw  \\\n",
       "count            5061.000000           5061.000000  5061.0   \n",
       "mean                0.429955              0.833235     0.0   \n",
       "std                 0.730263              1.284542     0.0   \n",
       "min                 0.000000              0.000000     0.0   \n",
       "25%                 0.000000              0.000000     0.0   \n",
       "50%                 0.000000              0.000000     0.0   \n",
       "75%                 1.000000              1.000000     0.0   \n",
       "max                 6.000000             12.000000     0.0   \n",
       "\n",
       "       B_longest_win_streak     B_losses  B_total_rounds_fought  \\\n",
       "count           5061.000000  5061.000000            5061.000000   \n",
       "mean               1.585062     1.462754               8.903972   \n",
       "std                1.771906     1.865975              11.242031   \n",
       "min                0.000000     0.000000               0.000000   \n",
       "25%                0.000000     0.000000               1.000000   \n",
       "50%                1.000000     1.000000               5.000000   \n",
       "75%                2.000000     2.000000              13.000000   \n",
       "max               16.000000    13.000000              75.000000   \n",
       "\n",
       "       B_total_title_bouts  B_win_by_Decision_Majority  \\\n",
       "count          5061.000000                 5061.000000   \n",
       "mean              0.277811                    0.016993   \n",
       "std               1.107056                    0.130777   \n",
       "min               0.000000                    0.000000   \n",
       "25%               0.000000                    0.000000   \n",
       "50%               0.000000                    0.000000   \n",
       "75%               0.000000                    0.000000   \n",
       "max              16.000000                    2.000000   \n",
       "\n",
       "       B_win_by_Decision_Split  B_win_by_Decision_Unanimous  ...  \\\n",
       "count              5061.000000                  5061.000000  ...   \n",
       "mean                  0.211421                     0.778502  ...   \n",
       "std                   0.525210                     1.294768  ...   \n",
       "min                   0.000000                     0.000000  ...   \n",
       "25%                   0.000000                     0.000000  ...   \n",
       "50%                   0.000000                     0.000000  ...   \n",
       "75%                   0.000000                     1.000000  ...   \n",
       "max                   5.000000                    10.000000  ...   \n",
       "\n",
       "       R_win_by_Decision_Unanimous  R_win_by_KO_TKO  R_win_by_Submission  \\\n",
       "count                  5061.000000      5061.000000          5061.000000   \n",
       "mean                      1.178423         1.254100             0.778502   \n",
       "std                       1.602733         1.792344             1.327774   \n",
       "min                       0.000000         0.000000             0.000000   \n",
       "25%                       0.000000         0.000000             0.000000   \n",
       "50%                       1.000000         1.000000             0.000000   \n",
       "75%                       2.000000         2.000000             1.000000   \n",
       "max                      10.000000        11.000000            13.000000   \n",
       "\n",
       "       R_win_by_TKO_Doctor_Stoppage       R_wins  R_Height_cms  R_Reach_cms  \\\n",
       "count                   5061.000000  5061.000000   5057.000000  4752.000000   \n",
       "mean                       0.071725     3.600869    179.293763   183.682837   \n",
       "std                        0.278677     3.708439      8.651769    10.309217   \n",
       "min                        0.000000     0.000000    152.400000   152.400000   \n",
       "25%                        0.000000     1.000000    172.720000   177.800000   \n",
       "50%                        0.000000     2.000000    180.340000   185.420000   \n",
       "75%                        0.000000     5.000000    185.420000   190.500000   \n",
       "max                        2.000000    20.000000    210.820000   213.360000   \n",
       "\n",
       "       R_Weight_lbs        B_age        R_age  \n",
       "count   5058.000000  4891.000000  4998.000000  \n",
       "mean     172.075326    29.175833    29.427371  \n",
       "std       35.168220     4.078995     4.140642  \n",
       "min      115.000000    18.000000    19.000000  \n",
       "25%      145.000000    26.000000    26.000000  \n",
       "50%      170.000000    29.000000    29.000000  \n",
       "75%      185.000000    32.000000    32.000000  \n",
       "max      345.000000    51.000000    47.000000  \n",
       "\n",
       "[8 rows x 36 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing Constant columns\n",
    "Constant columns have no variation and therefore does not contribute to our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distinguishing between  categorical and numeric columns\n",
    "\n",
    "categorical = list(df.select_dtypes(include=['object']))\n",
    "numeric = df.columns.tolist()\n",
    "constants = []\n",
    "for c in categorical:\n",
    "    numeric.remove(c)\n",
    "for col in numeric:\n",
    "    if min(df[col]) == max(df[col]):\n",
    "        constants.append(col)\n",
    "if len(constants)>0: \n",
    "    df.drop(columns = constants, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get count of na and null in each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Get count of na and null in each column\n",
    "#df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping NA values in stance\n",
    "df.dropna(subset = ['R_Stance', 'B_Stance'], inplace = True, axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Replacing the nan of height with its median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"B_Height_cms\"] = df[\"B_Height_cms\"].fillna(value=df[\"B_Height_cms\"].median())\n",
    "df[\"R_Height_cms\"] = df[\"R_Height_cms\"].fillna(value=df[\"R_Height_cms\"].median())\n",
    "df[\"B_Reach_cms\"] = df[\"B_Reach_cms\"].fillna(value=df[\"B_Reach_cms\"].median())\n",
    "df[\"R_Reach_cms\"] = df[\"R_Reach_cms\"].fillna(value=df[\"R_Reach_cms\"].median())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropping the missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(axis=0, inplace=True)\n",
    "df.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.columns.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4635, 40)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One hot encoding "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before encoding Winner(target variabel) we are encoding R Stance and B Stance. This will help us with binary classification later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting columns to be encoded\n",
    "toBeEncoded = ['B_Stance','R_Stance']\n",
    "df_encoded = df[toBeEncoded]\n",
    "\n",
    "# Encoding the data\n",
    "df_encoded = pd.get_dummies(df_encoded)\n",
    "\n",
    "# Renaming the encoding columns\n",
    "df_encoded.rename(columns={\n",
    "    \"B_Stance_Open Stance\": \"B_Stance_Open_Stance\",\n",
    "    \"R_Stance_Open Stance\": \"R_Stance_Open_Stance\"},inplace=True)\n",
    "\n",
    "# Droping the initial uncoded fields\n",
    "df.drop(toBeEncoded, axis=1, inplace=True) \n",
    "\n",
    "# Concatenating the encoded dataframe at the end\n",
    "df = pd.concat([df,df_encoded],1)\n",
    "#df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding Blue = 1 and Red = 0\n",
    "**Since this is a binary classification we are replacing Blue with value 1 and Red with value 0. 1 means that the winner of the fight was the B_fighter.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Winner'] = df['Winner'].replace(['Blue', 'Red'], [1, 0]).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffling the data\n",
    "df_processed = df.sample(frac=1, random_state=110).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Testing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3708, 43)\n",
      "(927, 43)\n"
     ]
    }
   ],
   "source": [
    "X = df_processed.drop(columns=['Winner', 'date', 'B_fighter', 'R_fighter']).copy()\n",
    "y = df_processed['Winner']\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=130)\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random forests or random decision forests are an ensemble learning method for classification, regression and other tasks that operate by constructing a multitude of decision trees at training time and outputting the class that is the mode of the classes (classification) or mean/average prediction (regression) of all the output of the decision trees.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialising Random Forest \n",
    "rf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimising Random Forest By Tuning Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**n_estimators = number of trees in the foreset<br>\n",
    "max_features = max number of features considered for splitting a node<br>\n",
    "max_depth = max number of levels in each decision tree<br>\n",
    "min_samples_split = min number of data points placed in a node before the node is split<br>\n",
    "min_samples_leaf = min number of data points allowed in a leaf node<br>\n",
    "bootstrap = method for sampling data points (with or without replacement)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'n_estimators': [100, 200, 400],\n",
    "               'max_features': ['sqrt', 'auto'],\n",
    "               'max_depth': [10, 20, 30],\n",
    "               'min_samples_split': [3, 5, 10],\n",
    "               'min_samples_leaf': [1, 2, 4],\n",
    "               'bootstrap': [True, False]}\n",
    "\n",
    "grid_rf = GridSearchCV(rf, param_grid, cv=3, verbose=0, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, estimator=RandomForestClassifier(),\n",
       "             param_grid={'bootstrap': [True, False], 'max_depth': [10, 20, 30],\n",
       "                         'max_features': ['sqrt', 'auto'],\n",
       "                         'min_samples_leaf': [1, 2, 4],\n",
       "                         'min_samples_split': [3, 5, 10],\n",
       "                         'n_estimators': [100, 200, 400]},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_rf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation using Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.96      0.82       644\n",
      "           1       0.53      0.11      0.18       283\n",
      "\n",
      "    accuracy                           0.70       927\n",
      "   macro avg       0.62      0.53      0.50       927\n",
      "weighted avg       0.66      0.70      0.62       927\n",
      "\n",
      "AUC:  0.5338075851019467\n",
      "Accuracy Score:  0.6990291262135923\n"
     ]
    }
   ],
   "source": [
    "pred_rf_pipeline = grid_rf.predict(x_test) \n",
    "print(classification_report(y_test, pred_rf_pipeline))\n",
    "print(\"AUC: \",roc_auc_score(y_test, pred_rf_pipeline))\n",
    "print(\"Accuracy Score: \",accuracy_score(y_test, pred_rf_pipeline))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After tuning the hyperparameter we get an accuraacy of 0.7 and recall of 0.96 for Random Forest. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Support Vector Machine (SVM) is a widely-used supervised machine learning algorithm. It is mostly used in classification tasks but suitable for regression tasks as well.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialising SVM Forest \n",
    "lin_svm = svm.LinearSVC()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimising SVM By Tuning Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**C parameter adds a penalty for each misclassified data point. If c is small, the penalty for misclassified points is low so a decision boundary with a large margin is chosen at the expense of a greater number of misclassifications. If c is large, SVM tries to minimize the number of misclassified examples due to high penalty which results in a decision boundary with a smaller margin.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'C':[0.001,0.01,0.1,1.0,10,100,1000],'penalty':['l2','l1']}\n",
    "grid_svm = GridSearchCV(lin_svm, param_grid, cv=3, verbose=0, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sahebsingh/anaconda3/lib/python3.7/site-packages/sklearn/svm/_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/sahebsingh/anaconda3/lib/python3.7/site-packages/sklearn/svm/_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/sahebsingh/anaconda3/lib/python3.7/site-packages/sklearn/svm/_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/sahebsingh/anaconda3/lib/python3.7/site-packages/sklearn/svm/_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/sahebsingh/anaconda3/lib/python3.7/site-packages/sklearn/svm/_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/sahebsingh/anaconda3/lib/python3.7/site-packages/sklearn/svm/_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/sahebsingh/anaconda3/lib/python3.7/site-packages/sklearn/svm/_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/sahebsingh/anaconda3/lib/python3.7/site-packages/sklearn/svm/_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/sahebsingh/anaconda3/lib/python3.7/site-packages/sklearn/svm/_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/sahebsingh/anaconda3/lib/python3.7/site-packages/sklearn/svm/_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/sahebsingh/anaconda3/lib/python3.7/site-packages/sklearn/svm/_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/sahebsingh/anaconda3/lib/python3.7/site-packages/sklearn/svm/_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/sahebsingh/anaconda3/lib/python3.7/site-packages/sklearn/svm/_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/sahebsingh/anaconda3/lib/python3.7/site-packages/sklearn/svm/_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/sahebsingh/anaconda3/lib/python3.7/site-packages/sklearn/svm/_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/sahebsingh/anaconda3/lib/python3.7/site-packages/sklearn/svm/_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/sahebsingh/anaconda3/lib/python3.7/site-packages/sklearn/svm/_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/sahebsingh/anaconda3/lib/python3.7/site-packages/sklearn/svm/_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/sahebsingh/anaconda3/lib/python3.7/site-packages/sklearn/svm/_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/sahebsingh/anaconda3/lib/python3.7/site-packages/sklearn/svm/_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/sahebsingh/anaconda3/lib/python3.7/site-packages/sklearn/svm/_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/sahebsingh/anaconda3/lib/python3.7/site-packages/sklearn/svm/_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, estimator=LinearSVC(),\n",
       "             param_grid={'C': [0.001, 0.01, 0.1, 1.0, 10, 100, 1000],\n",
       "                         'penalty': ['l2']},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_svm.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation using Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.96      0.82       644\n",
      "           1       0.57      0.12      0.19       283\n",
      "\n",
      "    accuracy                           0.70       927\n",
      "   macro avg       0.64      0.54      0.51       927\n",
      "weighted avg       0.67      0.70      0.63       927\n",
      "\n",
      "AUC:  0.5388939490375962\n",
      "Accuracy Score:  0.703344120819849\n"
     ]
    }
   ],
   "source": [
    "#Predicting using Pipeline\n",
    "pred_lin_pipeline = grid_svm.predict(x_test) \n",
    "print(classification_report(y_test, pred_lin_pipeline))\n",
    "print(\"AUC: \",roc_auc_score(y_test, pred_lin_pipeline))\n",
    "print(\"Accuracy Score: \",accuracy_score(y_test, pred_lin_pipeline))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get accuracy of 0.7 and recall of 0.96 which is similar to that of Random Forest. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Boosting algorithms play a crucial role in dealing with bias variance trade-off.  Unlike bagging algorithms, which only controls for high variance in a model, boosting controls both the aspects (bias & variance), and is considered to be more effective.  A sincere understanding of GBM here should give you much needed confidence to deal with such critical issues.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialising Gradiet Boosting Classifier \n",
    "xgbClf = XGBClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimising Gradient Boosting By Tuning Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**min_samples_split: Defines the minimum number of samples (or observations) which are required in a node to be considered for splitting.<br>\n",
    "min_samples_leaf: Defines the minimum samples (or observations) required in a terminal node or leaf.Used to control over-fitting similar to min_samples_split.Generally lower values should be chosen for imbalanced class problems because the regions in which the minority class will be in majority will be very small.<br>\n",
    "min_weight_fraction_leaf: Similar to min_samples_leaf but defined as a fraction of the total number of observations instead of an integer. <br>\n",
    "max_depth: The maximum depth of a tree.Used to control over-fitting as higher depth will allow model to learn relations very specific to a particular sample.<br>\n",
    "max_leaf_nodes: The maximum number of terminal nodes or leaves in a tree.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'learning_rate':[0.15,0.1,0.05,0.005,0.001], \n",
    "              'n_estimators':[100,250,500,750,1000],\n",
    "              'max_depth':[2,3,4,5,6,7],\n",
    "              'min_child_weight': [1, 5, 10],\n",
    "              'gamma': [0.5, 1, 1.5, 2, 5]}\n",
    "\n",
    "grid_xgb = GridSearchCV(xgbClf, param_grid, cv=3, verbose=0, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grid_xgb.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation using Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.95      0.82       644\n",
      "           1       0.58      0.14      0.23       283\n",
      "\n",
      "    accuracy                           0.71       927\n",
      "   macro avg       0.65      0.55      0.53       927\n",
      "weighted avg       0.67      0.71      0.64       927\n",
      "\n",
      "AUC:  0.5491462370783311\n",
      "Accuracy Score:  0.7065803667745415\n"
     ]
    }
   ],
   "source": [
    "pred_xgb_pipeline = grid_xgb.predict(x_test) \n",
    "print(classification_report(y_test, pred_xgb_pipeline))\n",
    "print(\"AUC: \",roc_auc_score(y_test, pred_xgb_pipeline))\n",
    "print(\"Accuracy Score: \",accuracy_score(y_test, pred_xgb_pipeline))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get accuracy of 0.71, recall of 0.95 and AUC od 0.54."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra Tree Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extremely Randomized Trees, or Extra Trees for short, is an ensemble machine learning algorithm.\n",
    "Specifically, it is an ensemble of decision trees and is related to other ensembles of decision trees algorithms such as bootstrap aggregation (bagging) and random forest.\n",
    "The Extra Trees algorithm works by creating a large number of unpruned decision trees from the training dataset. Predictions are made by averaging the prediction of the decision trees in the case of regression or using majority voting in the case of classification.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialising Extra Tree Classifier \n",
    "et = ExtraTreesClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimising Extra Tree By Tuning Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**n_estimator:The number of trees in the forest.<br>\n",
    "max_features: The number of features to consider when looking for the best split.<br>\n",
    "max_depth: The maximum depth of the tree. If None, then nodes are expanded until all leaves are pure or until all leaves contain less than min_samples_split samples.<br>\n",
    "min_samples_leaf: The minimum number of samples required to be at a leaf node. A split point at any depth will only be considered if it leaves at least min_samples_leaf training samples in each of the left and right branches.<br> \n",
    "bootstrapbool: Whether bootstrap samples are used when building trees. If False, the whole dataset is used to build each tree.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'n_estimators': [100, 200, 400],\n",
    "               'max_features': ['sqrt', 'auto'],\n",
    "               'max_depth': [10, 20, 30],\n",
    "               'min_samples_split': [3, 5, 10],\n",
    "               'bootstrap': [True, False]}\n",
    "\n",
    "grid_et = GridSearchCV(et, param_grid, cv=3, verbose=0, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, estimator=ExtraTreesClassifier(),\n",
       "             param_grid={'bootstrap': [True, False], 'max_depth': [10, 20, 30],\n",
       "                         'max_features': ['sqrt', 'auto'],\n",
       "                         'min_samples_split': [3, 5, 10],\n",
       "                         'n_estimators': [100, 200, 400]},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_et.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation using Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.95      0.82       644\n",
      "           1       0.54      0.13      0.22       283\n",
      "\n",
      "    accuracy                           0.70       927\n",
      "   macro avg       0.63      0.54      0.52       927\n",
      "weighted avg       0.66      0.70      0.63       927\n",
      "\n",
      "AUC:  0.5422930886903847\n",
      "Accuracy Score:  0.7011866235167206\n"
     ]
    }
   ],
   "source": [
    "pred_et_pipeline = grid_et.predict(x_test) \n",
    "print(classification_report(y_test, pred_et_pipeline))\n",
    "print(\"AUC: \",roc_auc_score(y_test, pred_et_pipeline))\n",
    "print(\"Accuracy Score: \",accuracy_score(y_test, pred_et_pipeline))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get an accuracy of 0.70, recall of 0.95 and AUC of 0.54."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naïve Bayes Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In statistics, Naive Bayes classifiers are a family of simple \"probabilistic classifiers\" based on applying Bayes' theorem with strong independence assumptions between the features. They are among the simplest Bayesian network models, but coupled with Kernel density estimation, they can achieve higher accuracy levels.<br>\n",
    "MultinomialNB implements the naive Bayes algorithm for multinomially distributed data, and is one of the two classic naive Bayes variants used in text classification (where the data are typically represented as word vector counts, although tf-idf vectors are also known to work well in practice).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB, MultinomialNB\n",
    "mnb = MultinomialNB(alpha=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimising Naïve Bayes Classification By Tuning Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**alpha: Additive (Laplace/Lidstone) smoothing parameter (0 for no smoothing).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'alpha' : [0.5,1.0,2]\n",
    "}\n",
    "grid_mnb = GridSearchCV(mnb, param_grid, cv=3, verbose=0, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, estimator=MultinomialNB(),\n",
       "             param_grid={'alpha': [0.5, 1.0, 2]}, scoring='accuracy')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_mnb.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation using Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.70      0.72       644\n",
      "           1       0.40      0.46      0.43       283\n",
      "\n",
      "    accuracy                           0.63       927\n",
      "   macro avg       0.57      0.58      0.58       927\n",
      "weighted avg       0.64      0.63      0.63       927\n",
      "\n",
      "AUC:  0.5796232688804513\n",
      "Accuracy Score:  0.627831715210356\n"
     ]
    }
   ],
   "source": [
    "pred_mnb_pipeline = grid_mnb.predict(x_test) \n",
    "print(classification_report(y_test, pred_mnb_pipeline))\n",
    "print(\"AUC: \",roc_auc_score(y_test, pred_mnb_pipeline))\n",
    "print(\"Accuracy Score: \",accuracy_score(y_test, pred_mnb_pipeline))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get a lower accuracy of 0.63, recall of 0.70 and AUC of 0.57."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Neural Network "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A Sequential model is appropriate for a plain stack of layers where each layer has exactly one input tensor and one output tensor.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling data for Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(x_train)\n",
    "X_train_scaled = scaler.transform(x_train)\n",
    "X_test_scaled = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing Neural Network "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dropout is regularization technique to avoid overfitting (increase the validation accuracy) thus increasing the generalizing power.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modeling\n",
    "dnnClf = Sequential()\n",
    "\n",
    "# First hiden layer\n",
    "dnnClf.add(Dense(units=20,activation='relu'))\n",
    "# Second hiden layer\n",
    "dnnClf.add(Dense(units=10, activation='relu'))\n",
    "# Adding Dropout\n",
    "dnnClf.add(Dropout(0.5))\n",
    "# Output layer\n",
    "dnnClf.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "dnnClf.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping \n",
    "early_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Neural Netowork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.7260 - accuracy: 0.5359 - val_loss: 0.6520 - val_accuracy: 0.6926\n",
      "Epoch 2/1000\n",
      "116/116 [==============================] - 0s 859us/step - loss: 0.6515 - accuracy: 0.6691 - val_loss: 0.6258 - val_accuracy: 0.6947\n",
      "Epoch 3/1000\n",
      "116/116 [==============================] - 0s 854us/step - loss: 0.6437 - accuracy: 0.6739 - val_loss: 0.6197 - val_accuracy: 0.6947\n",
      "Epoch 4/1000\n",
      "116/116 [==============================] - 0s 870us/step - loss: 0.6334 - accuracy: 0.6742 - val_loss: 0.6148 - val_accuracy: 0.6947\n",
      "Epoch 5/1000\n",
      "116/116 [==============================] - 0s 834us/step - loss: 0.6357 - accuracy: 0.6739 - val_loss: 0.6149 - val_accuracy: 0.6947\n",
      "Epoch 6/1000\n",
      "116/116 [==============================] - 0s 852us/step - loss: 0.6296 - accuracy: 0.6745 - val_loss: 0.6091 - val_accuracy: 0.6936\n",
      "Epoch 7/1000\n",
      "116/116 [==============================] - 0s 862us/step - loss: 0.6274 - accuracy: 0.6777 - val_loss: 0.6057 - val_accuracy: 0.6958\n",
      "Epoch 8/1000\n",
      "116/116 [==============================] - 0s 812us/step - loss: 0.6269 - accuracy: 0.6799 - val_loss: 0.6023 - val_accuracy: 0.7012\n",
      "Epoch 9/1000\n",
      "116/116 [==============================] - 0s 833us/step - loss: 0.6230 - accuracy: 0.6783 - val_loss: 0.5995 - val_accuracy: 0.6990\n",
      "Epoch 10/1000\n",
      "116/116 [==============================] - 0s 820us/step - loss: 0.6181 - accuracy: 0.6793 - val_loss: 0.5951 - val_accuracy: 0.7023\n",
      "Epoch 11/1000\n",
      "116/116 [==============================] - 0s 835us/step - loss: 0.6122 - accuracy: 0.6810 - val_loss: 0.5944 - val_accuracy: 0.7033\n",
      "Epoch 12/1000\n",
      "116/116 [==============================] - 0s 845us/step - loss: 0.6139 - accuracy: 0.6810 - val_loss: 0.5915 - val_accuracy: 0.7023\n",
      "Epoch 13/1000\n",
      "116/116 [==============================] - 0s 822us/step - loss: 0.6134 - accuracy: 0.6826 - val_loss: 0.5895 - val_accuracy: 0.6980\n",
      "Epoch 14/1000\n",
      "116/116 [==============================] - 0s 817us/step - loss: 0.6083 - accuracy: 0.6799 - val_loss: 0.5885 - val_accuracy: 0.7033\n",
      "Epoch 15/1000\n",
      "116/116 [==============================] - 0s 834us/step - loss: 0.6101 - accuracy: 0.6777 - val_loss: 0.5876 - val_accuracy: 0.7001\n",
      "Epoch 16/1000\n",
      "116/116 [==============================] - 0s 879us/step - loss: 0.6069 - accuracy: 0.6850 - val_loss: 0.5902 - val_accuracy: 0.6990\n",
      "Epoch 17/1000\n",
      "116/116 [==============================] - 0s 873us/step - loss: 0.6033 - accuracy: 0.6885 - val_loss: 0.5892 - val_accuracy: 0.6980\n",
      "Epoch 18/1000\n",
      "116/116 [==============================] - 0s 862us/step - loss: 0.6044 - accuracy: 0.6858 - val_loss: 0.5853 - val_accuracy: 0.7044\n",
      "Epoch 19/1000\n",
      "116/116 [==============================] - 0s 894us/step - loss: 0.6024 - accuracy: 0.6861 - val_loss: 0.5867 - val_accuracy: 0.7033\n",
      "Epoch 20/1000\n",
      "116/116 [==============================] - 0s 871us/step - loss: 0.5999 - accuracy: 0.6820 - val_loss: 0.5864 - val_accuracy: 0.7033\n",
      "Epoch 21/1000\n",
      "116/116 [==============================] - 0s 916us/step - loss: 0.6010 - accuracy: 0.6855 - val_loss: 0.5853 - val_accuracy: 0.7044\n",
      "Epoch 22/1000\n",
      "116/116 [==============================] - 0s 807us/step - loss: 0.6023 - accuracy: 0.6845 - val_loss: 0.5862 - val_accuracy: 0.7023\n",
      "Epoch 23/1000\n",
      "116/116 [==============================] - 0s 813us/step - loss: 0.5998 - accuracy: 0.6899 - val_loss: 0.5824 - val_accuracy: 0.7044\n",
      "Epoch 24/1000\n",
      "116/116 [==============================] - 0s 840us/step - loss: 0.5976 - accuracy: 0.6891 - val_loss: 0.5813 - val_accuracy: 0.7066\n",
      "Epoch 25/1000\n",
      "116/116 [==============================] - 0s 860us/step - loss: 0.5973 - accuracy: 0.6872 - val_loss: 0.5807 - val_accuracy: 0.7098\n",
      "Epoch 26/1000\n",
      "116/116 [==============================] - 0s 837us/step - loss: 0.5942 - accuracy: 0.6888 - val_loss: 0.5852 - val_accuracy: 0.6969\n",
      "Epoch 27/1000\n",
      "116/116 [==============================] - 0s 823us/step - loss: 0.5989 - accuracy: 0.6874 - val_loss: 0.5802 - val_accuracy: 0.7131\n",
      "Epoch 28/1000\n",
      "116/116 [==============================] - 0s 825us/step - loss: 0.5956 - accuracy: 0.6912 - val_loss: 0.5803 - val_accuracy: 0.7098\n",
      "Epoch 29/1000\n",
      "116/116 [==============================] - 0s 849us/step - loss: 0.5943 - accuracy: 0.6885 - val_loss: 0.5808 - val_accuracy: 0.7055\n",
      "Epoch 30/1000\n",
      "116/116 [==============================] - 0s 807us/step - loss: 0.5957 - accuracy: 0.6891 - val_loss: 0.5800 - val_accuracy: 0.7109\n",
      "Epoch 31/1000\n",
      "116/116 [==============================] - 0s 811us/step - loss: 0.5943 - accuracy: 0.6909 - val_loss: 0.5795 - val_accuracy: 0.7055\n",
      "Epoch 32/1000\n",
      "116/116 [==============================] - 0s 828us/step - loss: 0.5949 - accuracy: 0.6842 - val_loss: 0.5786 - val_accuracy: 0.7131\n",
      "Epoch 33/1000\n",
      "116/116 [==============================] - 0s 821us/step - loss: 0.5922 - accuracy: 0.6928 - val_loss: 0.5795 - val_accuracy: 0.7012\n",
      "Epoch 34/1000\n",
      "116/116 [==============================] - 0s 816us/step - loss: 0.5916 - accuracy: 0.6950 - val_loss: 0.5786 - val_accuracy: 0.7087\n",
      "Epoch 35/1000\n",
      "116/116 [==============================] - 0s 818us/step - loss: 0.5915 - accuracy: 0.6874 - val_loss: 0.5842 - val_accuracy: 0.6936\n",
      "Epoch 36/1000\n",
      "116/116 [==============================] - 0s 816us/step - loss: 0.5957 - accuracy: 0.6866 - val_loss: 0.5799 - val_accuracy: 0.7055\n",
      "Epoch 37/1000\n",
      "116/116 [==============================] - 0s 815us/step - loss: 0.5967 - accuracy: 0.6874 - val_loss: 0.5801 - val_accuracy: 0.7077\n",
      "Epoch 38/1000\n",
      "116/116 [==============================] - 0s 879us/step - loss: 0.5930 - accuracy: 0.6896 - val_loss: 0.5815 - val_accuracy: 0.6980\n",
      "Epoch 39/1000\n",
      "116/116 [==============================] - 0s 914us/step - loss: 0.5913 - accuracy: 0.6931 - val_loss: 0.5777 - val_accuracy: 0.7077\n",
      "Epoch 40/1000\n",
      "116/116 [==============================] - 0s 860us/step - loss: 0.5912 - accuracy: 0.6912 - val_loss: 0.5783 - val_accuracy: 0.7109\n",
      "Epoch 41/1000\n",
      "116/116 [==============================] - 0s 861us/step - loss: 0.5862 - accuracy: 0.6893 - val_loss: 0.5771 - val_accuracy: 0.7109\n",
      "Epoch 42/1000\n",
      "116/116 [==============================] - 0s 820us/step - loss: 0.5927 - accuracy: 0.6928 - val_loss: 0.5792 - val_accuracy: 0.7087\n",
      "Epoch 43/1000\n",
      "116/116 [==============================] - 0s 854us/step - loss: 0.5940 - accuracy: 0.6845 - val_loss: 0.5773 - val_accuracy: 0.7120\n",
      "Epoch 44/1000\n",
      "116/116 [==============================] - 0s 887us/step - loss: 0.5918 - accuracy: 0.6926 - val_loss: 0.5778 - val_accuracy: 0.7023\n",
      "Epoch 45/1000\n",
      "116/116 [==============================] - 0s 876us/step - loss: 0.5900 - accuracy: 0.6917 - val_loss: 0.5753 - val_accuracy: 0.7098\n",
      "Epoch 46/1000\n",
      "116/116 [==============================] - 0s 883us/step - loss: 0.5863 - accuracy: 0.7004 - val_loss: 0.5744 - val_accuracy: 0.7131\n",
      "Epoch 47/1000\n",
      "116/116 [==============================] - 0s 839us/step - loss: 0.5863 - accuracy: 0.6944 - val_loss: 0.5758 - val_accuracy: 0.7044\n",
      "Epoch 48/1000\n",
      "116/116 [==============================] - 0s 856us/step - loss: 0.5879 - accuracy: 0.6971 - val_loss: 0.5753 - val_accuracy: 0.7109\n",
      "Epoch 49/1000\n",
      "116/116 [==============================] - 0s 906us/step - loss: 0.5920 - accuracy: 0.6909 - val_loss: 0.5761 - val_accuracy: 0.7120\n",
      "Epoch 50/1000\n",
      "116/116 [==============================] - 0s 815us/step - loss: 0.5881 - accuracy: 0.6955 - val_loss: 0.5744 - val_accuracy: 0.7131\n",
      "Epoch 51/1000\n",
      "116/116 [==============================] - 0s 862us/step - loss: 0.5857 - accuracy: 0.6950 - val_loss: 0.5774 - val_accuracy: 0.7001\n",
      "Epoch 52/1000\n",
      "116/116 [==============================] - 0s 862us/step - loss: 0.5848 - accuracy: 0.6969 - val_loss: 0.5765 - val_accuracy: 0.7066\n",
      "Epoch 53/1000\n",
      "116/116 [==============================] - 0s 863us/step - loss: 0.5863 - accuracy: 0.6961 - val_loss: 0.5754 - val_accuracy: 0.7012\n",
      "Epoch 54/1000\n",
      "116/116 [==============================] - 0s 838us/step - loss: 0.5853 - accuracy: 0.6950 - val_loss: 0.5720 - val_accuracy: 0.7109\n",
      "Epoch 55/1000\n",
      "116/116 [==============================] - 0s 863us/step - loss: 0.5853 - accuracy: 0.6990 - val_loss: 0.5723 - val_accuracy: 0.7141\n",
      "Epoch 56/1000\n",
      "116/116 [==============================] - 0s 863us/step - loss: 0.5842 - accuracy: 0.7017 - val_loss: 0.5734 - val_accuracy: 0.7109\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/1000\n",
      "116/116 [==============================] - 0s 901us/step - loss: 0.5819 - accuracy: 0.7033 - val_loss: 0.5715 - val_accuracy: 0.7163\n",
      "Epoch 58/1000\n",
      "116/116 [==============================] - 0s 859us/step - loss: 0.5826 - accuracy: 0.6953 - val_loss: 0.5727 - val_accuracy: 0.7098\n",
      "Epoch 59/1000\n",
      "116/116 [==============================] - 0s 886us/step - loss: 0.5790 - accuracy: 0.7017 - val_loss: 0.5721 - val_accuracy: 0.7131\n",
      "Epoch 60/1000\n",
      "116/116 [==============================] - 0s 901us/step - loss: 0.5786 - accuracy: 0.6998 - val_loss: 0.5731 - val_accuracy: 0.7109\n",
      "Epoch 61/1000\n",
      "116/116 [==============================] - 0s 854us/step - loss: 0.5840 - accuracy: 0.6971 - val_loss: 0.5740 - val_accuracy: 0.7120\n",
      "Epoch 62/1000\n",
      "116/116 [==============================] - 0s 867us/step - loss: 0.5767 - accuracy: 0.7044 - val_loss: 0.5714 - val_accuracy: 0.7098\n",
      "Epoch 63/1000\n",
      "116/116 [==============================] - 0s 868us/step - loss: 0.5792 - accuracy: 0.6993 - val_loss: 0.5720 - val_accuracy: 0.7120\n",
      "Epoch 64/1000\n",
      "116/116 [==============================] - 0s 886us/step - loss: 0.5790 - accuracy: 0.6980 - val_loss: 0.5702 - val_accuracy: 0.7120\n",
      "Epoch 65/1000\n",
      "116/116 [==============================] - 0s 838us/step - loss: 0.5800 - accuracy: 0.7009 - val_loss: 0.5700 - val_accuracy: 0.7044\n",
      "Epoch 66/1000\n",
      "116/116 [==============================] - 0s 860us/step - loss: 0.5800 - accuracy: 0.6936 - val_loss: 0.5721 - val_accuracy: 0.7044\n",
      "Epoch 67/1000\n",
      "116/116 [==============================] - 0s 898us/step - loss: 0.5787 - accuracy: 0.6993 - val_loss: 0.5725 - val_accuracy: 0.7001\n",
      "Epoch 68/1000\n",
      "116/116 [==============================] - 0s 840us/step - loss: 0.5756 - accuracy: 0.7050 - val_loss: 0.5708 - val_accuracy: 0.7109\n",
      "Epoch 69/1000\n",
      "116/116 [==============================] - 0s 829us/step - loss: 0.5753 - accuracy: 0.6993 - val_loss: 0.5729 - val_accuracy: 0.7098\n",
      "Epoch 70/1000\n",
      "116/116 [==============================] - 0s 856us/step - loss: 0.5715 - accuracy: 0.7069 - val_loss: 0.5735 - val_accuracy: 0.7087\n",
      "Epoch 71/1000\n",
      "116/116 [==============================] - 0s 824us/step - loss: 0.5765 - accuracy: 0.6993 - val_loss: 0.5719 - val_accuracy: 0.7066\n",
      "Epoch 72/1000\n",
      "116/116 [==============================] - 0s 841us/step - loss: 0.5730 - accuracy: 0.7006 - val_loss: 0.5715 - val_accuracy: 0.7131\n",
      "Epoch 73/1000\n",
      "116/116 [==============================] - 0s 859us/step - loss: 0.5773 - accuracy: 0.7006 - val_loss: 0.5717 - val_accuracy: 0.7087\n",
      "Epoch 74/1000\n",
      "116/116 [==============================] - 0s 945us/step - loss: 0.5718 - accuracy: 0.7066 - val_loss: 0.5750 - val_accuracy: 0.7055\n",
      "Epoch 75/1000\n",
      "116/116 [==============================] - 0s 840us/step - loss: 0.5723 - accuracy: 0.7033 - val_loss: 0.5710 - val_accuracy: 0.7109\n",
      "Epoch 76/1000\n",
      "116/116 [==============================] - 0s 851us/step - loss: 0.5720 - accuracy: 0.7015 - val_loss: 0.5696 - val_accuracy: 0.7120\n",
      "Epoch 77/1000\n",
      "116/116 [==============================] - 0s 876us/step - loss: 0.5778 - accuracy: 0.6990 - val_loss: 0.5719 - val_accuracy: 0.7098\n",
      "Epoch 78/1000\n",
      "116/116 [==============================] - 0s 839us/step - loss: 0.5707 - accuracy: 0.7006 - val_loss: 0.5707 - val_accuracy: 0.7055\n",
      "Epoch 79/1000\n",
      "116/116 [==============================] - 0s 885us/step - loss: 0.5689 - accuracy: 0.7082 - val_loss: 0.5689 - val_accuracy: 0.7131\n",
      "Epoch 80/1000\n",
      "116/116 [==============================] - 0s 872us/step - loss: 0.5698 - accuracy: 0.7055 - val_loss: 0.5680 - val_accuracy: 0.7131\n",
      "Epoch 81/1000\n",
      "116/116 [==============================] - 0s 843us/step - loss: 0.5745 - accuracy: 0.7023 - val_loss: 0.5686 - val_accuracy: 0.7163\n",
      "Epoch 82/1000\n",
      "116/116 [==============================] - 0s 863us/step - loss: 0.5759 - accuracy: 0.7017 - val_loss: 0.5750 - val_accuracy: 0.7098\n",
      "Epoch 83/1000\n",
      "116/116 [==============================] - 0s 865us/step - loss: 0.5700 - accuracy: 0.7066 - val_loss: 0.5694 - val_accuracy: 0.7098\n",
      "Epoch 84/1000\n",
      "116/116 [==============================] - 0s 848us/step - loss: 0.5709 - accuracy: 0.7095 - val_loss: 0.5756 - val_accuracy: 0.7066\n",
      "Epoch 85/1000\n",
      "116/116 [==============================] - 0s 824us/step - loss: 0.5667 - accuracy: 0.7093 - val_loss: 0.5751 - val_accuracy: 0.7098\n",
      "Epoch 86/1000\n",
      "116/116 [==============================] - 0s 823us/step - loss: 0.5722 - accuracy: 0.7033 - val_loss: 0.5713 - val_accuracy: 0.7120\n",
      "Epoch 87/1000\n",
      "116/116 [==============================] - 0s 836us/step - loss: 0.5651 - accuracy: 0.7106 - val_loss: 0.5703 - val_accuracy: 0.7152\n",
      "Epoch 88/1000\n",
      "116/116 [==============================] - 0s 973us/step - loss: 0.5701 - accuracy: 0.7044 - val_loss: 0.5705 - val_accuracy: 0.7141\n",
      "Epoch 89/1000\n",
      "116/116 [==============================] - 0s 845us/step - loss: 0.5640 - accuracy: 0.7087 - val_loss: 0.5693 - val_accuracy: 0.7131\n",
      "Epoch 90/1000\n",
      "116/116 [==============================] - 0s 915us/step - loss: 0.5662 - accuracy: 0.7050 - val_loss: 0.5700 - val_accuracy: 0.7131\n",
      "Epoch 91/1000\n",
      "116/116 [==============================] - 0s 810us/step - loss: 0.5655 - accuracy: 0.7155 - val_loss: 0.5707 - val_accuracy: 0.7098\n",
      "Epoch 92/1000\n",
      "116/116 [==============================] - 0s 812us/step - loss: 0.5658 - accuracy: 0.7109 - val_loss: 0.5735 - val_accuracy: 0.7141\n",
      "Epoch 93/1000\n",
      "116/116 [==============================] - 0s 820us/step - loss: 0.5672 - accuracy: 0.7106 - val_loss: 0.5732 - val_accuracy: 0.7098\n",
      "Epoch 94/1000\n",
      "116/116 [==============================] - 0s 806us/step - loss: 0.5713 - accuracy: 0.7079 - val_loss: 0.5712 - val_accuracy: 0.7120\n",
      "Epoch 95/1000\n",
      "116/116 [==============================] - 0s 836us/step - loss: 0.5642 - accuracy: 0.7090 - val_loss: 0.5744 - val_accuracy: 0.7120\n",
      "Epoch 96/1000\n",
      "116/116 [==============================] - 0s 834us/step - loss: 0.5701 - accuracy: 0.7093 - val_loss: 0.5721 - val_accuracy: 0.7087\n",
      "Epoch 00096: early stopping\n"
     ]
    }
   ],
   "source": [
    "dnnClf.fit(x=X_train_scaled, \n",
    "          y=y_train, \n",
    "          epochs=1000,\n",
    "          validation_data=(X_test_scaled, y_test), verbose=1,\n",
    "          callbacks=[early_stop]\n",
    "          )\n",
    "model_loss = pd.DataFrame(dnnClf.history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_loss.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation using Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.94      0.82       644\n",
      "           1       0.58      0.17      0.27       283\n",
      "\n",
      "    accuracy                           0.71       927\n",
      "   macro avg       0.65      0.56      0.54       927\n",
      "weighted avg       0.68      0.71      0.65       927\n",
      "\n",
      "AUC:  0.5586221276035379\n",
      "Accuracy Score:  0.7087378640776699\n"
     ]
    }
   ],
   "source": [
    "dnnPreds = dnnClf.predict(scaler.transform(x_test))\n",
    "dnnPreds = [round(i[0]) for i in dnnPreds]\n",
    "print(classification_report(y_test, dnnPreds))\n",
    "print(\"AUC: \",roc_auc_score(y_test, dnnPreds))\n",
    "print(\"Accuracy Score: \",accuracy_score(y_test,dnnPreds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get an accuracy of 0.71, recall of 0.94 and AUC of 0.56."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Logistic regression is a statistical model that in its basic form uses a logistic function to model a binary dependent variable, although many more complex extensions exist. In regression analysis, logistic regression (or logit regression) is estimating the parameters of a logistic model (a form of binary regression).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialising Logistic Regression Classifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimising Logistic Regression by Tuning Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Binary Logistic Regression.<br>\n",
    "C: The C parameter controls the penality strength, which can also be effective.<br>\n",
    "max_iter: Number of iteration.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'max_iter': [100,200,400],\n",
    "    'C':[0.01,0.001,0.1,1]\n",
    "}\n",
    "grid_lr = GridSearchCV(lr, param_grid, cv=3, verbose=0, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sahebsingh/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/sahebsingh/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/sahebsingh/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/sahebsingh/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/sahebsingh/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/sahebsingh/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/sahebsingh/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/sahebsingh/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/sahebsingh/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/sahebsingh/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/sahebsingh/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/sahebsingh/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/sahebsingh/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/sahebsingh/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/sahebsingh/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/sahebsingh/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/sahebsingh/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/sahebsingh/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/sahebsingh/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sahebsingh/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/sahebsingh/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/sahebsingh/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/sahebsingh/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/sahebsingh/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/sahebsingh/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/sahebsingh/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/sahebsingh/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/sahebsingh/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/sahebsingh/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/sahebsingh/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/sahebsingh/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/sahebsingh/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/sahebsingh/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/sahebsingh/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/sahebsingh/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, estimator=LogisticRegression(),\n",
       "             param_grid={'C': [0.01, 0.001, 0.1, 1],\n",
       "                         'max_iter': [100, 200, 400]},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_lr.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation using Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.91      0.80       644\n",
      "           1       0.46      0.17      0.25       283\n",
      "\n",
      "    accuracy                           0.69       927\n",
      "   macro avg       0.59      0.54      0.52       927\n",
      "weighted avg       0.64      0.69      0.63       927\n",
      "\n",
      "AUC:  0.5405509953251542\n",
      "Accuracy Score:  0.6850053937432579\n"
     ]
    }
   ],
   "source": [
    "pred_lr_pipeline = grid_lr.predict(x_test) \n",
    "print(classification_report(y_test, pred_lr_pipeline))\n",
    "print(\"AUC: \",roc_auc_score(y_test, pred_lr_pipeline))\n",
    "print(\"Accuracy Score: \",accuracy_score(y_test, pred_lr_pipeline))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get an accuracy of 0.69, recall of 0.91 and AUC of 0.54."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K Means Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**k-means clustering is a method of vector quantization, originally from signal processing, that aims to partition n observations into k clusters in which each observation belongs to the cluster with the nearest mean, serving as a prototype of the cluster.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialising KMeans classification\n",
    "kmeans = KMeans()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimising K-Means \n",
    "**Applying KMeans mode with 2 clusters as our model should perform Binary Classification. Parameters: n_init means the number of time the algorithm will run with different centroids, max_iter means the maximum number of iteration Kmeans will perform.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=2, n_init=25, max_iter=100, random_state=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(max_iter=100, n_clusters=2, n_init=25, random_state=6)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans.fit(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation using Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.65      0.66       644\n",
      "           1       0.25      0.26      0.25       283\n",
      "\n",
      "    accuracy                           0.53       927\n",
      "   macro avg       0.46      0.46      0.46       927\n",
      "weighted avg       0.54      0.53      0.54       927\n",
      "\n",
      "AUC:  0.4560526084761759\n",
      "Accuracy Score:  0.5318230852211435\n"
     ]
    }
   ],
   "source": [
    "pred_kmeans = kmeans.predict(x_test)\n",
    "print(classification_report(y_test, pred_kmeans))\n",
    "print(\"AUC: \",roc_auc_score(y_test, pred_kmeans))\n",
    "print(\"Accuracy Score: \",accuracy_score(y_test, pred_kmeans))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get the lowest accuracy while using K Means with accuracy of 0.53 and recall of 0.65 where as we AUC score is 0.45. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Association Rule Mining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting Age into categorical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = df.describe()\n",
    "column_name = t.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in column_name:\n",
    "    df[i+\"grp\"] = pd.qcut(df[i], q=4,\n",
    "                                  labels = False,duplicates='drop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = ['B_current_lose_streak', 'B_current_win_streak',\n",
    "       'B_longest_win_streak', 'B_losses', 'B_total_rounds_fought',\n",
    "       'B_total_title_bouts', 'B_win_by_Decision_Majority',\n",
    "       'B_win_by_Decision_Split', 'B_win_by_Decision_Unanimous',\n",
    "       'B_win_by_KO_TKO', 'B_win_by_Submission',\n",
    "       'B_win_by_TKO_Doctor_Stoppage', 'B_wins', 'B_Height_cms', 'B_Reach_cms',\n",
    "       'B_Weight_lbs', 'R_current_lose_streak', 'R_current_win_streak',\n",
    "       'R_longest_win_streak', 'R_losses', 'R_total_rounds_fought',\n",
    "       'R_total_title_bouts', 'R_win_by_Decision_Majority',\n",
    "       'R_win_by_Decision_Split', 'R_win_by_Decision_Unanimous',\n",
    "       'R_win_by_KO_TKO', 'R_win_by_Submission',\n",
    "       'R_win_by_TKO_Doctor_Stoppage', 'R_wins', 'R_Height_cms', 'R_Reach_cms',\n",
    "       'R_Weight_lbs', 'B_age', 'R_age', 'B_Stance_Open_Stance',\n",
    "       'B_Stance_Orthodox', 'B_Stance_Sideways', 'B_Stance_Southpaw',\n",
    "       'B_Stance_Switch', 'R_Stance_Open_Stance', 'R_Stance_Orthodox',\n",
    "       'R_Stance_Southpaw', 'R_Stance_Switch']\n",
    "l = []\n",
    "for i in t:\n",
    "    l.append(i+'grp')\n",
    "l.append('Winner')\n",
    "not_used_columns = list(set(df.columns.to_list()) - set(l))\n",
    "df = pd.get_dummies(df, columns=l)\n",
    "df.drop(labels=not_used_columns, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Appriori with Tuned Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Applying Apriori with for Winner = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>antecedents</th>\n",
       "      <th>consequents</th>\n",
       "      <th>antecedent support</th>\n",
       "      <th>consequent support</th>\n",
       "      <th>support</th>\n",
       "      <th>confidence</th>\n",
       "      <th>lift</th>\n",
       "      <th>leverage</th>\n",
       "      <th>conviction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11268998</th>\n",
       "      <td>(R_total_title_boutsgrp_0, R_agegrp_3, B_Reach...</td>\n",
       "      <td>(Winner_1)</td>\n",
       "      <td>0.042934</td>\n",
       "      <td>0.322114</td>\n",
       "      <td>0.023085</td>\n",
       "      <td>0.537688</td>\n",
       "      <td>1.669247</td>\n",
       "      <td>0.009256</td>\n",
       "      <td>1.466296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13417564</th>\n",
       "      <td>(R_total_title_boutsgrp_0, R_agegrp_3, R_Heigh...</td>\n",
       "      <td>(Winner_1)</td>\n",
       "      <td>0.039914</td>\n",
       "      <td>0.322114</td>\n",
       "      <td>0.021359</td>\n",
       "      <td>0.535135</td>\n",
       "      <td>1.661320</td>\n",
       "      <td>0.008502</td>\n",
       "      <td>1.458242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10657102</th>\n",
       "      <td>(R_agegrp_3, B_Reach_cmsgrp_0, B_Height_cmsgrp_0)</td>\n",
       "      <td>(Winner_1)</td>\n",
       "      <td>0.038188</td>\n",
       "      <td>0.322114</td>\n",
       "      <td>0.020280</td>\n",
       "      <td>0.531073</td>\n",
       "      <td>1.648711</td>\n",
       "      <td>0.007980</td>\n",
       "      <td>1.445612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13872624</th>\n",
       "      <td>(R_win_by_Submissiongrp_0, R_Reach_cmsgrp_0, R...</td>\n",
       "      <td>(Winner_1)</td>\n",
       "      <td>0.043581</td>\n",
       "      <td>0.322114</td>\n",
       "      <td>0.022869</td>\n",
       "      <td>0.524752</td>\n",
       "      <td>1.629088</td>\n",
       "      <td>0.008831</td>\n",
       "      <td>1.426384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2436160</th>\n",
       "      <td>(B_current_win_streakgrp_1, R_lossesgrp_2, R_t...</td>\n",
       "      <td>(Winner_1)</td>\n",
       "      <td>0.043366</td>\n",
       "      <td>0.322114</td>\n",
       "      <td>0.022654</td>\n",
       "      <td>0.522388</td>\n",
       "      <td>1.621747</td>\n",
       "      <td>0.008685</td>\n",
       "      <td>1.419323</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                antecedents consequents  \\\n",
       "11268998  (R_total_title_boutsgrp_0, R_agegrp_3, B_Reach...  (Winner_1)   \n",
       "13417564  (R_total_title_boutsgrp_0, R_agegrp_3, R_Heigh...  (Winner_1)   \n",
       "10657102  (R_agegrp_3, B_Reach_cmsgrp_0, B_Height_cmsgrp_0)  (Winner_1)   \n",
       "13872624  (R_win_by_Submissiongrp_0, R_Reach_cmsgrp_0, R...  (Winner_1)   \n",
       "2436160   (B_current_win_streakgrp_1, R_lossesgrp_2, R_t...  (Winner_1)   \n",
       "\n",
       "          antecedent support  consequent support   support  confidence  \\\n",
       "11268998            0.042934            0.322114  0.023085    0.537688   \n",
       "13417564            0.039914            0.322114  0.021359    0.535135   \n",
       "10657102            0.038188            0.322114  0.020280    0.531073   \n",
       "13872624            0.043581            0.322114  0.022869    0.524752   \n",
       "2436160             0.043366            0.322114  0.022654    0.522388   \n",
       "\n",
       "              lift  leverage  conviction  \n",
       "11268998  1.669247  0.009256    1.466296  \n",
       "13417564  1.661320  0.008502    1.458242  \n",
       "10657102  1.648711  0.007980    1.445612  \n",
       "13872624  1.629088  0.008831    1.426384  \n",
       "2436160   1.621747  0.008685    1.419323  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Apriori min support\n",
    "min_support = 0.02 # Since the number of Attrition = Yes is so less, min_support also needs to be small \n",
    "\n",
    "#Max lenght of apriori n-grams\n",
    "max_len = 3\n",
    "\n",
    "frequent_items = apriori(df, use_colnames=True, min_support=min_support, max_len=max_len + 1)\n",
    "rules = association_rules(frequent_items, metric='lift', min_threshold=1)\n",
    "\n",
    "target = '{\\'Winner_1\\'}'\n",
    "\n",
    "results_attrition_yes = rules[rules['consequents'].astype(str).str.contains(target, na=False)].sort_values(by='confidence', ascending=False)\n",
    "\n",
    "results_attrition_yes.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After looking at the top 5 rules we can see that fighters who are the defending the title, are of a old age typically more than 33 years, have a good reach, and have a good height are most likely to win the match. Therefore fighter's title, age group and height are important factors while determining if the fighter will win the fight or not. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Applying Apriori with for Winner = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>antecedents</th>\n",
       "      <th>consequents</th>\n",
       "      <th>antecedent support</th>\n",
       "      <th>consequent support</th>\n",
       "      <th>support</th>\n",
       "      <th>confidence</th>\n",
       "      <th>lift</th>\n",
       "      <th>leverage</th>\n",
       "      <th>conviction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1080543</th>\n",
       "      <td>(R_agegrp_0, R_current_lose_streakgrp_0, B_win...</td>\n",
       "      <td>(Winner_0)</td>\n",
       "      <td>0.265156</td>\n",
       "      <td>0.677886</td>\n",
       "      <td>0.205609</td>\n",
       "      <td>0.775427</td>\n",
       "      <td>1.143891</td>\n",
       "      <td>0.025864</td>\n",
       "      <td>1.434343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457416</th>\n",
       "      <td>(R_win_by_Submissiongrp_0, R_agegrp_0, R_curre...</td>\n",
       "      <td>(Winner_0)</td>\n",
       "      <td>0.268177</td>\n",
       "      <td>0.677886</td>\n",
       "      <td>0.207120</td>\n",
       "      <td>0.772325</td>\n",
       "      <td>1.139315</td>\n",
       "      <td>0.025326</td>\n",
       "      <td>1.414799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70036</th>\n",
       "      <td>(B_Reach_cmsgrp_1, R_Stance_Switchgrp_0)</td>\n",
       "      <td>(Winner_0)</td>\n",
       "      <td>0.277023</td>\n",
       "      <td>0.677886</td>\n",
       "      <td>0.213161</td>\n",
       "      <td>0.769470</td>\n",
       "      <td>1.135104</td>\n",
       "      <td>0.025371</td>\n",
       "      <td>1.397280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1398504</th>\n",
       "      <td>(B_Reach_cmsgrp_1, R_win_by_Decision_Splitgrp_...</td>\n",
       "      <td>(Winner_0)</td>\n",
       "      <td>0.277023</td>\n",
       "      <td>0.677886</td>\n",
       "      <td>0.213161</td>\n",
       "      <td>0.769470</td>\n",
       "      <td>1.135104</td>\n",
       "      <td>0.025371</td>\n",
       "      <td>1.397280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1401990</th>\n",
       "      <td>(B_Reach_cmsgrp_1, B_Stance_Orthodoxgrp_0, B_S...</td>\n",
       "      <td>(Winner_0)</td>\n",
       "      <td>0.277023</td>\n",
       "      <td>0.677886</td>\n",
       "      <td>0.213161</td>\n",
       "      <td>0.769470</td>\n",
       "      <td>1.135104</td>\n",
       "      <td>0.025371</td>\n",
       "      <td>1.397280</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               antecedents consequents  \\\n",
       "1080543  (R_agegrp_0, R_current_lose_streakgrp_0, B_win...  (Winner_0)   \n",
       "1457416  (R_win_by_Submissiongrp_0, R_agegrp_0, R_curre...  (Winner_0)   \n",
       "70036             (B_Reach_cmsgrp_1, R_Stance_Switchgrp_0)  (Winner_0)   \n",
       "1398504  (B_Reach_cmsgrp_1, R_win_by_Decision_Splitgrp_...  (Winner_0)   \n",
       "1401990  (B_Reach_cmsgrp_1, B_Stance_Orthodoxgrp_0, B_S...  (Winner_0)   \n",
       "\n",
       "         antecedent support  consequent support   support  confidence  \\\n",
       "1080543            0.265156            0.677886  0.205609    0.775427   \n",
       "1457416            0.268177            0.677886  0.207120    0.772325   \n",
       "70036              0.277023            0.677886  0.213161    0.769470   \n",
       "1398504            0.277023            0.677886  0.213161    0.769470   \n",
       "1401990            0.277023            0.677886  0.213161    0.769470   \n",
       "\n",
       "             lift  leverage  conviction  \n",
       "1080543  1.143891  0.025864    1.434343  \n",
       "1457416  1.139315  0.025326    1.414799  \n",
       "70036    1.135104  0.025371    1.397280  \n",
       "1398504  1.135104  0.025371    1.397280  \n",
       "1401990  1.135104  0.025371    1.397280  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Apriori min support\n",
    "min_support = 0.2 \n",
    "\n",
    "#Max lenght of apriori n-grams\n",
    "max_len = 3\n",
    "\n",
    "frequent_items = apriori(df, use_colnames=True, min_support=min_support, max_len=max_len + 1)\n",
    "#frequent_items = ap.apriori(df, min_support=0.8, min_confidence=0.8,\n",
    "#                              min_lift=1,min_length=2)\n",
    "rules = association_rules(frequent_items, metric='lift', min_threshold=1)\n",
    "\n",
    "target = '{\\'Winner_0\\'}'\n",
    "\n",
    "results_attrition_no = rules[rules['consequents'].astype(str).str.contains(target, na=False)].sort_values(by='confidence', ascending=False)\n",
    "\n",
    "results_attrition_no.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After looking at the top 5 rules we can see that fighters who are young belonging to age group 0, have a good winning streak, and have a lose streak of 0 are most likely to loose the match. Therefore fighter's age group, winning or loosing streakare important factors while determining if the fighter will win the fight or not. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Looking at all our model's accuracy we see that we get the highest accuracy of 0.71 using Neural Network and Random Forest. With the lowest accuracy being 0.53 which we got using K Means. Since the UFC's model is able to predict the winner correctly only 57% of the time. We have increased the accuracy using our machine learning model to 71%.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
